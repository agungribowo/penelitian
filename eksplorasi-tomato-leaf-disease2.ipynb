{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263da2d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Tugas: Eksplorasi dan Reproduksi Model Deteksi Penyakit Daun Tomat\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Tujuan Notebook:**\\n\",\n",
    "    \"1.  **Reproduksi:** Mereplikasi hasil dari notebook Kaggle referensi ([Tomato Leaf Disease (94% accuracy)](https://www.kaggle.com/code/samanfatima7/tomato-leaf-disease-94-accuracy)) yang menggunakan Custom CNN.\\n\",\n",
    "    \"2.  **Eksplorasi:** Mencoba meningkatkan performa model menggunakan teknik Transfer Learning (EfficientNetB0) dan Fine-Tuning.\\n\",\n",
    "    \"3.  **Perbandingan:** Menganalisis dan membandingkan hasil dari ketiga pendekatan tersebut.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Langkah 1: Setup Lingkungan & Download Dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"Pertama, kita akan menginstal library Kaggle, mengautentikasi, dan mengunduh dataset yang diperlukan langsung ke lingkungan Colab.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Installing Kaggle library...\\\")\\n\",\n",
    "    \"!pip install -q kaggle\\n\",\n",
    "    \"\\n\",\n",
    "    \"from google.colab import files\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nPlease upload your kaggle.json file\\\")\\n\",\n",
    "    \"files.upload() # Upload your kaggle.json API token here\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Setup direktori Kaggle\\n\",\n",
    "    \"!mkdir -p ~/.kaggle\\n\",\n",
    "    \"!cp kaggle.json ~/.kaggle/\\n\",\n",
    "    \"!chmod 600 ~/.kaggle/kaggle.json\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nDownloading and unzipping the dataset...\\\")\\n\",\n",
    "    \"# Download dataset dari Kaggle\\n\",\n",
    "    \"!kaggle datasets download -d farukalam/tomato-leaf-diseases-detection-computer-vision -p /content/ --unzip\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nDataset ready.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Langkah 2: Import Library dan Definisikan Parameter\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\",\n",
    "    \"from tensorflow.keras.models import Sequential, Model\\n\",\n",
    "    \"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\\n\",\n",
    "    \"from tensorflow.keras.applications import EfficientNetB0\\n\",\n",
    "    \"from tensorflow.keras.optimizers import Adam\\n\",\n",
    "    \"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Definisikan Konstanta\\n\",\n",
    "    \"TRAIN_DIR = '/content/tomato/train'\\n\",\n",
    "    \"VAL_DIR = '/content/tomato/val'\\n\",\n",
    "    \"IMG_SIZE = (128, 128)\\n\",\n",
    "    \"BATCH_SIZE = 32\\n\",\n",
    "    \"NUM_CLASSES = 11\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Bagian 1: Reproduksi Model Baseline (Custom CNN)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Di bagian ini, kita akan mereplikasi arsitektur dan proses training dari notebook Kaggle referensi.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"--- Preparing Data for Baseline Model ---\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Gunakan ImageDataGenerator seperti di notebook referensi\\n\",\n",
    "    \"train_datagen_baseline = ImageDataGenerator(\\n\",\n",
    "    \"    rescale=1./255,\\n\",\n",
    "    \"    shear_range=0.2,\\n\",\n",
    "    \"    zoom_range=0.2,\\n\",\n",
    "    \"    horizontal_flip=True\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"val_datagen_baseline = ImageDataGenerator(rescale=1./255)\\n\",\n",
    "    \"\\n\",\n",
    "    \"train_generator_baseline = train_datagen_baseline.flow_from_directory(\\n\",\n",
    "    \"    TRAIN_DIR,\\n\",\n",
    "    \"    target_size=IMG_SIZE,\\n\",\n",
    "    \"    batch_size=BATCH_SIZE,\\n\",\n",
    "    \"    class_mode='categorical'\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"validation_generator_baseline = val_datagen_baseline.flow_from_directory(\\n\",\n",
    "    \"    VAL_DIR,\\n\",\n",
    "    \"    target_size=IMG_SIZE,\\n\",\n",
    "    \"    batch_size=BATCH_SIZE,\\n\",\n",
    "    \"    class_mode='categorical',\\n\",\n",
    "    \"    shuffle=False\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"--- Building Baseline CNN Model ---\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"baseline_model = Sequential([\\n\",\n",
    "    \"    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\\n\",\n",
    "    \"    MaxPooling2D(2, 2),\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Conv2D(64, (3, 3), activation='relu'),\\n\",\n",
    "    \"    MaxPooling2D(2, 2),\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Conv2D(128, (3, 3), activation='relu'),\\n\",\n",
    "    \"    MaxPooling2D(2, 2),\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Flatten(),\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Dense(128, activation='relu'),\\n\",\n",
    "    \"    Dense(NUM_CLASSES, activation='softmax')\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"baseline_model.compile(\\n\",\n",
    "    \"    optimizer='adam',\\n\",\n",
    "    \"    loss='categorical_crossentropy',\\n\",\n",
    "    \"    metrics=['accuracy']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"baseline_model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"--- Training Baseline CNN Model ---\\\")\\n\",\n",
    "    \"# Latih untuk epoch lebih sedikit agar cepat, notebook asli 50 epoch\\n\",\n",
    "    \"EPOCHS_BASELINE = 25 \\n\",\n",
    "    \"\\n\",\n",
    "    \"history_baseline = baseline_model.fit(\\n\",\n",
    "    \"    train_generator_baseline,\\n\",\n",
    "    \"    epochs=EPOCHS_BASELINE,\\n\",\n",
    "    \"    validation_data=validation_generator_baseline\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"--- Evaluating Baseline Model ---\\\")\\n\",\n",
    "    \"results_baseline = baseline_model.evaluate(validation_generator_baseline)\\n\",\n",
    "    \"print(f\\\"Baseline Model Validation Loss: {results_baseline[0]:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Baseline Model Validation Accuracy: {results_baseline[1]*100:.2f}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Bagian 2: Eksplorasi dengan Transfer Learning & Fine-Tuning\\n\",\n",
    "    \"\\n\",\n",
    "    \"Sekarang kita akan menggunakan model pra-terlatih (EfficientNetB0) untuk mendapatkan performa yang lebih tinggi.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"--- Preparing Data for Transfer Learning Model ---\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Untuk transfer learning, kita hanya perlu normalisasi. Augmentasi akan dilakukan oleh lapisan Keras.\\n\",\n",
    "    \"train_datagen_tl = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\\n\",\n",
    "    \"val_datagen_tl = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\\n\",\n",
    "    \"\\n\",\n",
    "    \"train_generator_tl = train_datagen_tl.flow_from_directory(\\n\",\n",
    "    \"    TRAIN_DIR,\\n\",\n",
    "    \"    target_size=IMG_SIZE,\\n\",\n",
    "    \"    batch_size=BATCH_SIZE,\\n\",\n",
    "    \"    class_mode='categorical'\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"validation_generator_tl = val_datagen_tl.flow_from_directory(\\n\",\n",
    "    \"    VAL_DIR,\\n\",\n",
    "    \"    target_size=IMG_SIZE,\\n\",\n",
    "    \"    batch_size=BATCH_SIZE,\\n\",\n",
    "    \"    class_mode='categorical',\\n\",\n",
    "    \"    shuffle=False\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"--- Building Transfer Learning Model (EfficientNetB0) ---\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 1. Muat Base Model\\n\",\n",
    "    \"base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\\n\",\n",
    "    \"base_model.trainable = False # Bekukan bobot base model\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 2. Tambahkan Lapisan Augmentasi dan Classifier baru\\n\",\n",
    "    \"data_augmentation = Sequential([\\n\",\n",
    "    \"    tf.keras.layers.RandomFlip('horizontal'),\\n\",\n",
    "    \"    tf.keras.layers.RandomRotation(0.2),\\n\",\n",
    "    \"    tf.keras.layers.RandomZoom(0.2),\\n\",\n",
    "    \"], name='data_augmentation')\\n\",\n",
    "    \"\\n\",\n",
    "    \"inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\\n\",\n",
    "    \"x = data_augmentation(inputs)\\n\",\n",
    "    \"x = base_model(x, training=False) # Pastikan base model dalam inference mode\\n\",\n",
    "    \"x = GlobalAveragePooling2D()(x)\\n\",\n",
    "    \"x = Dropout(0.5)(x)\\n\",\n",
    "    \"outputs = Dense(NUM_CLASSES, activation='softmax')(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"tl_model = Model(inputs, outputs)\\n\",\n",
    "    \"\\n\",\n",
    "    \"tl_model.compile(\\n\",\n",
    "    \"    optimizer=Adam(learning_rate=1e-3),\\n\",\n",
    "    \"    loss='categorical_crossentropy',\\n\",\n",
    "    \"    metrics=['accuracy']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"tl_model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"--- Training Transfer Learning Model (Phase 1: Feature Extraction) ---\\\")\\n\",\n",
    "    \"EPOCHS_TL = 15\\n\",\n",
    "    \"\\n\",\n",
    "    \"history_tl = tl_model.fit(\\n\",\n",
    "    \"    train_generator_tl,\\n\",\n",
    "    \"    epochs=EPOCHS_TL,\\n\",\n",
    "    \"    validation_data=validation_generator_tl\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Fine-Tuning\\n\",\n",
    "    \"\\n\",\n",
    "    \"Setelah model konvergen pada lapisan baru, kita akan 'mencairkan' beberapa lapisan teratas dari base model dan melatihnya kembali dengan learning rate yang sangat kecil.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"--- Fine-Tuning the Transfer Learning Model (Phase 2) ---\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Cairkan base model\\n\",\n",
    "    \"base_model.trainable = True\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Bekukan semua lapisan kecuali 20 terakhir\\n\",\n",
    "    \"for layer in base_model.layers[:-20]:\\n\",\n",
    "    \"    layer.trainable = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Kompilasi ulang dengan learning rate yang sangat kecil\\n\",\n",
    "    \"tl_model.compile(\\n\",\n",
    "    \"    optimizer=Adam(learning_rate=1e-5), \\n\",\n",
    "    \"    loss='categorical_crossentropy',\\n\",\n",
    "    \"    metrics=['accuracy']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"tl_model.summary()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Lanjutkan pelatihan\\n\",\n",
    "    \"EPOCHS_FT = 10\\n\",\n",
    "    \"history_ft = tl_model.fit(\\n\",\n",
    "    \"    train_generator_tl,\\n\",\n",
    "    \"    epochs=EPOCHS_TL + EPOCHS_FT, # Lanjutkan dari epoch sebelumnya\\n\",\n",
    "    \"    initial_epoch=history_tl.epoch[-1] + 1,\\n\",\n",
    "    \"    validation_data=validation_generator_tl\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"--- Evaluating Fine-Tuned Model ---\\\")\\n\",\n",
    "    \"results_ft = tl_model.evaluate(validation_generator_tl)\\n\",\n",
    "    \"print(f\\\"Fine-Tuned Model Validation Loss: {results_ft[0]:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Fine-Tuned Model Validation Accuracy: {results_ft[1]*100:.2f}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Bagian 3: Kesimpulan dan Perbandingan Hasil\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=========================================================\\\")\\n\",\n",
    "    \"print(\\\"               PERBANDINGAN AKHIR HASIL                  \\\")\\n\",\n",
    "    \"print(\\\"=========================================================\\\")\\n\",\n",
    "    \"print(f\\\"Model Baseline (Custom CNN): \\\\t{results_baseline[1]*100:.2f}% Akurasi Validasi\\\")\\n\",\n",
    "    \"print(f\\\"Model Fine-Tuned (EfficientNetB0): \\\\t{results_ft[1]*100:.2f}% Akurasi Validasi\\\")\\n\",\n",
    "    \"print(\\\"=========================================================\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Menggabungkan history untuk plot\\n\",\n",
    "    \"acc = history_baseline.history['accuracy'] + history_tl.history['accuracy'] + history_ft.history['accuracy']\\n\",\n",
    "    \"val_acc = history_baseline.history['val_accuracy'] + history_tl.history['val_accuracy'] + history_ft.history['val_accuracy']\\n\",\n",
    "    \"loss = history_baseline.history['loss'] + history_tl.history['loss'] + history_ft.history['loss']\\n\",\n",
    "    \"val_loss = history_baseline.history['val_loss'] + history_tl.history['val_loss'] + history_ft.history['val_loss']\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(16, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot Akurasi\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.plot(history_baseline.history['val_accuracy'], label='Baseline Val Acc')\\n\",\n",
    "    \"plt.plot(history_tl.history['val_accuracy'] + history_ft.history['val_accuracy'], label='Transfer Learning Val Acc', color='orange')\\n\",\n",
    "    \"plt.axvline(EPOCHS_TL, color='grey', linestyle='--', label='Start Fine-Tuning')\\n\",\n",
    "    \"plt.title('Perbandingan Akurasi Validasi')\\n\",\n",
    "    \"plt.xlabel('Epoch')\\n\",\n",
    "    \"plt.ylabel('Akurasi')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot Loss\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"plt.plot(history_baseline.history['val_loss'], label='Baseline Val Loss')\\n\",\n",
    "    \"plt.plot(history_tl.history['val_loss'] + history_ft.history['val_loss'], label='Transfer Learning Val Loss', color='orange')\\n\",\n",
    "    \"plt.axvline(EPOCHS_TL, color='grey', linestyle='--', label='Start Fine-Tuning')\\n\",\n",
    "    \"plt.title('Perbandingan Loss Validasi')\\n\",\n",
    "    \"plt.xlabel('Epoch')\\n\",\n",
    "    \"plt.ylabel('Loss')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
